{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNr4ZnNUlTkUWxnS8unMRTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nourhanOfTerra/CIFAR-10/blob/main/CIFAR10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CIFAR-10 Classification Model: Convolutional Neural Networks\n",
        "\n",
        "Source 1: https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c\n",
        "\n",
        "Source 2: https://www.tensorflow.org/tutorials/images/cnn\n",
        "\n",
        "Source 3: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
        "\n",
        "Source 4: https://neptune.ai/blog/keras-metrics\n"
      ],
      "metadata": {
        "id": "sWBfVQMzXun7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mounting Google Drive"
      ],
      "metadata": {
        "id": "1L01YKsWXt2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YXvZq_OXaai",
        "outputId": "75a27c3d-5050-4c78-d87f-788b0c042aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/CIFAR-10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuOC_n6FrYRz"
      },
      "source": [
        "##Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorflow==2.7.0\n",
        "!pip3 install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np5muKtUGTIy",
        "outputId": "db02ea26-5fcb-426f-9e2b-f2d3d2b5a94c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.7.0\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 21 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Collecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.25.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYqv80wtUTp_"
      },
      "source": [
        "###General Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OF7ZOOF6rgw9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0uGS4YUUPMD"
      },
      "source": [
        "###Model Specific Libraris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Oqd-bOlbUOqI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from time import time\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQPPJG_epm2Y"
      },
      "source": [
        "##Importing the data from csv files to variables\n",
        "Note that since we are applying CNNs here, no need for feature extraction. Therefore, we should use the original features as they are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-X70qDJpprrP"
      },
      "outputs": [],
      "source": [
        "df_features = pd.read_csv('features.csv')\n",
        "df_labels = pd.read_csv('labels.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now converting to numpy arrays as they are easier to deal with in the upcoming functions of the scikit-learn library."
      ],
      "metadata": {
        "id": "oaj2KTTV7LsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_features.to_numpy()\n",
        "labels = df_labels.to_numpy()"
      ],
      "metadata": {
        "id": "pK2-6Usg5OUs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalizing the features\n",
        "This would be useful for the activation functions."
      ],
      "metadata": {
        "id": "e1T4Gb1Abfyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "normalized_features = scaler.fit_transform(features)"
      ],
      "metadata": {
        "id": "KT6SJbWGbfyq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoding the labels using one-hot encoding\n",
        "The reason for that is that there is no real relation between the integer values in the original labels vector and the labels. This might be misleading for the model. One hot encoding might be better in this case."
      ],
      "metadata": {
        "id": "mhoVGiAecf3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder(sparse = False)\n",
        "encoded_labels = encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "6doyzeBpcnfS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reshaping the feature matrix for Tensorflow\n"
      ],
      "metadata": {
        "id": "4Cqwe1GNUX7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_features = np.reshape(normalized_features, (60000, 3, 32, 32))\n",
        "transposed_features = reshaped_features.transpose(0, 2, 3, 1)"
      ],
      "metadata": {
        "id": "olQweoOSUda5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensuring results reproducibility"
      ],
      "metadata": {
        "id": "Dqti_ojlRavw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "#SEED = 20\n",
        "#os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "#random.seed(SEED)\n",
        "#np.random.seed(SEED)\n",
        "#tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "KzGgBJ3sRl18"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting the parameters"
      ],
      "metadata": {
        "id": "Mudg9s8YQHtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 32                                                                       # Don't Change\n",
        "BATCHES = 32\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.001\n",
        "ACTIVATION = 'relu'\n",
        "FILTER = (3, 3)                                                                 # Don't Change\n",
        "POOLING = (1, 1)                                                                # Don't Change\n",
        "OPTIMIZER = 'adam'\n",
        "LOSS = tf.keras.losses.CategoricalCrossentropy(from_logits = True)              \n",
        "METRICS = ['accuracy']\n",
        "TEST = 10000/60000                                                              # Don't Change\n",
        "VALIDATION = 10000/50000                                                        # Don't Change\n",
        "INPUT_SHAPE = (32, 32, 3)                                                       # Don't Change\n",
        "OUTPUTS = 10                                                                    # Don't Change"
      ],
      "metadata": {
        "id": "2h5Yl73NNGHy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dividing the dataset into training, validation and testing sets"
      ],
      "metadata": {
        "id": "CONf33Njjv0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(transposed_features, encoded_labels, test_size = TEST)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = VALIDATION)"
      ],
      "metadata": {
        "id": "04MPM0URjwEQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the model"
      ],
      "metadata": {
        "id": "-iK3EebA_P4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Convolutional and MaxPooling layers"
      ],
      "metadata": {
        "id": "pnjXCbYYCsyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(SIZE, FILTER, activation = ACTIVATION, input_shape = INPUT_SHAPE))             # First convolution layer\n",
        "model.add(layers.MaxPooling2D(POOLING))                                                                # First MaxPooling\n",
        "model.add(layers.Conv2D(2*SIZE, FILTER, activation = ACTIVATION))                                      # Second convolution layer\n",
        "model.add(layers.MaxPooling2D(POOLING))                                                                # Second MaxPooling\n",
        "model.add(layers.Conv2D(2*SIZE, FILTER, activation = ACTIVATION))\n",
        "model.add(layers.MaxPooling2D(POOLING))                                                                \n",
        "model.add(layers.Conv2D(2*SIZE, FILTER, activation = ACTIVATION))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbODduIv_vHP",
        "outputId": "55502053-e71e-44d6-e001-1d522cae376b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,248\n",
            "Trainable params: 93,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dense layers"
      ],
      "metadata": {
        "id": "asJ82Sp1D36j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())                                 # Flattening because input to this layer is 3D Tensor\n",
        "model.add(layers.Dense(2*SIZE, activation = ACTIVATION))    \n",
        "model.add(layers.Dense(OUTPUTS))                            # Output layer (10 outputs for 10 classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7lIvD6cD67t",
        "outputId": "133001a0-ed36-47a5-c2e0-929aa67a698a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36864)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2359360   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,453,258\n",
            "Trainable params: 2,453,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Early Stopping and Model Checkpoint callback functions"
      ],
      "metadata": {
        "id": "1nwq0wGRqxZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 10, verbose = 1, min_delta = 0.01)\n",
        "check_point = ModelCheckpoint('best_cnn.h5', monitor = 'val_accuracy', mode = 'max', save_best_only = True, verbose = 1)\n",
        "CALLBACKS = [early_stopping, check_point]"
      ],
      "metadata": {
        "id": "i8LWR_xOqaPt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "mV_KERjhFpl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = OPTIMIZER, loss = LOSS, metrics = METRICS)\n",
        "fitted_model = model.fit(X_train, y_train, batch_size = BATCHES, epochs = EPOCHS, validation_data = (X_val, y_val), callbacks = CALLBACKS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AYuRIVeFtyG",
        "outputId": "009e0cdc-9ac7-4c14-976f-a0bc76d5d5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.5229 - accuracy: 0.4494\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.55930, saving model to best_cnn.h5\n",
            "1250/1250 [==============================] - 317s 253ms/step - loss: 1.5229 - accuracy: 0.4494 - val_loss: 1.2400 - val_accuracy: 0.5593\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 1.0944 - accuracy: 0.6133\n",
            "Epoch 00002: val_accuracy improved from 0.55930 to 0.64810, saving model to best_cnn.h5\n",
            "1250/1250 [==============================] - 316s 252ms/step - loss: 1.0944 - accuracy: 0.6133 - val_loss: 1.0146 - val_accuracy: 0.6481\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.6876\n",
            "Epoch 00003: val_accuracy improved from 0.64810 to 0.65410, saving model to best_cnn.h5\n",
            "1250/1250 [==============================] - 308s 247ms/step - loss: 0.8850 - accuracy: 0.6876 - val_loss: 0.9826 - val_accuracy: 0.6541\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.7164 - accuracy: 0.7498\n",
            "Epoch 00004: val_accuracy improved from 0.65410 to 0.67410, saving model to best_cnn.h5\n",
            "1250/1250 [==============================] - 311s 248ms/step - loss: 0.7164 - accuracy: 0.7498 - val_loss: 0.9756 - val_accuracy: 0.6741\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.8152\n",
            "Epoch 00005: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 308s 246ms/step - loss: 0.5264 - accuracy: 0.8152 - val_loss: 1.0404 - val_accuracy: 0.6708\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8733\n",
            "Epoch 00006: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 319s 255ms/step - loss: 0.3608 - accuracy: 0.8733 - val_loss: 1.3073 - val_accuracy: 0.6525\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9200\n",
            "Epoch 00007: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 311s 249ms/step - loss: 0.2292 - accuracy: 0.9200 - val_loss: 1.5539 - val_accuracy: 0.6373\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9422\n",
            "Epoch 00008: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 310s 248ms/step - loss: 0.1686 - accuracy: 0.9422 - val_loss: 1.9085 - val_accuracy: 0.6389\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9546\n",
            "Epoch 00009: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 311s 249ms/step - loss: 0.1321 - accuracy: 0.9546 - val_loss: 2.1289 - val_accuracy: 0.6391\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9662\n",
            "Epoch 00010: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 311s 249ms/step - loss: 0.1008 - accuracy: 0.9662 - val_loss: 2.5838 - val_accuracy: 0.6272\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9635\n",
            "Epoch 00011: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 312s 250ms/step - loss: 0.1060 - accuracy: 0.9635 - val_loss: 2.3310 - val_accuracy: 0.6391\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9721\n",
            "Epoch 00012: val_accuracy did not improve from 0.67410\n",
            "1250/1250 [==============================] - 323s 258ms/step - loss: 0.0828 - accuracy: 0.9721 - val_loss: 2.7048 - val_accuracy: 0.6335\n",
            "Epoch 13/100\n",
            "1226/1250 [============================>.] - ETA: 5s - loss: 0.0877 - accuracy: 0.9711"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation of the model on the testing set"
      ],
      "metadata": {
        "id": "8Zw-C_Os2Yke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fitted_model.history['accuracy'], label = 'accuracy')\n",
        "plt.plot(fitted_model.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.savefig('Accuracy vs Epochs Trial 7 activation = softmax at the end')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "QEKTcydkC1LJ",
        "outputId": "d3112d4f-da3c-4ac9-869b-aa0739fded01"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading the best model"
      ],
      "metadata": {
        "id": "Vhmx-5fL2VBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('best_cnn.h5')"
      ],
      "metadata": {
        "id": "hIYp3RqC2X2N"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "gtyDF0MKUcM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb795a91-ed17-4d8d-b860-7f2dd6af087e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5740000009536743\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "\n",
            "The confusion matrix: \n",
            "[[465  11 104  12  33   6   6  55 227  45]\n",
            " [ 21 697   6  11   5   3  15   4  37 144]\n",
            " [ 73   3 361 104 171  65 150  34  32  11]\n",
            " [ 24   6 131 235  64 356 104  60  22  23]\n",
            " [ 35   3  92  43 543  35  90 138   6   4]\n",
            " [  9   4  69 161  50 604  28  68   8   5]\n",
            " [ 11   7  72  55  86  19 769   5   1   9]\n",
            " [ 22   3  30  24 107  63   5 739   3  12]\n",
            " [134  25  32  10   2  10   1   8 763  23]\n",
            " [ 58 193  18  24  22   6   9  96  29 564]]\n",
            "\n",
            "The classification report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.48      0.51       964\n",
            "           1       0.73      0.74      0.74       943\n",
            "           2       0.39      0.36      0.38      1004\n",
            "           3       0.35      0.23      0.28      1025\n",
            "           4       0.50      0.55      0.52       989\n",
            "           5       0.52      0.60      0.56      1006\n",
            "           6       0.65      0.74      0.70      1034\n",
            "           7       0.61      0.73      0.67      1008\n",
            "           8       0.68      0.76      0.71      1008\n",
            "           9       0.67      0.55      0.61      1019\n",
            "\n",
            "    accuracy                           0.57     10000\n",
            "   macro avg       0.57      0.57      0.57     10000\n",
            "weighted avg       0.56      0.57      0.57     10000\n",
            "\n",
            "\n",
            "Test Accuracy: 0.574\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test,  y_test, verbose=3)\n",
        "print('Test Accuracy:', test_acc)\n",
        "y_predicted = best_model.predict(X_test, batch_size = BATCHES, verbose = 1)\n",
        "confused = confusion_matrix(np.argmax(y_test, axis = 1), np.argmax(y_predicted, axis = 1))\n",
        "print(\"\\nThe confusion matrix: \")\n",
        "print(confused)\n",
        "report = classification_report(np.argmax(y_test, axis = 1), np.argmax(y_predicted, axis = 1))\n",
        "print(\"\\nThe classification report: \")\n",
        "print(report)\n",
        "acc_score = accuracy_score(np.argmax(y_test, axis = 1), np.argmax(y_predicted, axis = 1))\n",
        "print(\"\\nTest Accuracy:\", acc_score)"
      ]
    }
  ]
}